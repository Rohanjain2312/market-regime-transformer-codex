{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Regime-Switching Transformer (Colab)\n",
    "\n",
    "This notebook clones the repo, installs dependencies, trains the model, evaluates it, and visualizes results. GPU is used automatically if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check\n",
    "!nvidia-smi || echo \"No GPU detected; running on CPU.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/Rohanjain2312/market-regime-transformer-codex.git\n",
    "%cd market-regime-transformer-codex/market_regime_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: set a custom seed\n",
    "import src.config as config\n",
    "cfg = config.get_config(seed=42)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (rolling validation, checkpoints saved under data/processed)\n",
    "!python -m src.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the first split checkpoint and save confusion matrix\n",
    "!python -m src.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regime transitions from the engineered dataset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src.data_loader import load_data\n",
    "from src.features import build_feature_windows\n",
    "from src.config import get_config\n",
    "from src.visualize import plot_regime_transitions\n",
    "\n",
    "cfg = get_config()\n",
    "raw = load_data(cfg)\n",
    "X, y_reg, y_cls = build_feature_windows(raw, cfg, target_col=\"SPY\")\n",
    "plot_path = cfg.processed_data_path / \"regime_transitions.png\"\n",
    "plot_regime_transitions(y_cls, plot_path)\n",
    "print(f\"Saved regime transitions plot to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Visualize attention weights using a trained model\n",
    "import torch\n",
    "from src.model import RegimeTransformer\n",
    "from src.visualize import plot_attention\n",
    "\n",
    "feature_dim = X.shape[-1]\n",
    "model = RegimeTransformer(\n",
    "    input_dim=feature_dim,\n",
    "    d_model=cfg.embedding_dim,\n",
    "    nhead=cfg.num_heads,\n",
    "    num_layers=cfg.num_layers,\n",
    "    dim_feedforward=cfg.embedding_dim * 2,\n",
    "    dropout=cfg.dropout,\n",
    "    num_regimes=2,\n",
    ").to(cfg.device)\n",
    "\n",
    "ckpt = cfg.processed_data_path / \"best_model_split0.pt\"\n",
    "if ckpt.exists():\n",
    "    model.load_state_dict(torch.load(ckpt, map_location=cfg.device))\n",
    "    model.eval()\n",
    "    # Use a small batch to extract attention\n",
    "    sample = torch.tensor(X[:4], dtype=torch.float32).to(cfg.device)\n",
    "    _ = model(sample)\n",
    "    if hasattr(model, \"encoder\"):\n",
    "        # Access encoder layer attention via hooks not exposed here; this is a placeholder for custom hooks.\n",
    "        print(\"Model run complete. Add attention hooks in model if detailed maps are needed.\")\n",
    "else:\n",
    "    print(f\"Checkpoint {ckpt} not found. Train first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
